{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import sys\n",
    "from threading import Thread\n",
    "\n",
    "import pyaudio\n",
    "from picovoice import Picovoice\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import os\n",
    "from google.cloud import language_v1 as language\n",
    "\n",
    "from apa102 import APA102\n",
    "from gpiozero import LED\n",
    "\n",
    "COLORS_RGB = dict(\n",
    "    off=(0, 0, 0),\n",
    "    blue=(0, 0, 255),\n",
    "    green=(0, 255, 0),\n",
    "    orange=(255, 128, 0),\n",
    "    pink=(255, 51, 153),\n",
    "    purple=(128, 0, 128),\n",
    "    red=(255, 0, 0),\n",
    "    white=(255, 255, 255),\n",
    "    yellow=(255, 255, 51),\n",
    ")\n",
    "\n",
    "# Inicializacion LEDs\n",
    "driver = APA102(num_led=12)\n",
    "power = LED(5)\n",
    "power.on()\n",
    "\n",
    "class PicovoiceDemo(Thread):\n",
    "    def __init__(\n",
    "            self,\n",
    "            keyword_path,\n",
    "            context_path,\n",
    "            porcupine_sensitivity=0.75,\n",
    "            rhino_sensitivity=0.25):\n",
    "        super(PicovoiceDemo, self).__init__()\n",
    "\n",
    "        def inference_callback(inference):\n",
    "            return self._inference_callback(inference)\n",
    "\n",
    "        # Creacion objeto picovoice\n",
    "        self._picovoice = Picovoice(\n",
    "            keyword_path=keyword_path,\n",
    "            wake_word_callback=self._wake_word_callback,\n",
    "            context_path=context_path,\n",
    "            inference_callback=inference_callback,\n",
    "            porcupine_sensitivity=porcupine_sensitivity,\n",
    "            rhino_sensitivity=rhino_sensitivity)\n",
    "\n",
    "        self._context = self._picovoice.context_info\n",
    "\n",
    "        # Saludo\n",
    "        self._set_color(COLORS_RGB['purple'])\n",
    "        voz = AudioSegment.from_mp3(\"saludo.mp3\")\n",
    "        play(voz)\n",
    "        self._set_color(COLORS_RGB['off'])\n",
    "\n",
    "        # Se crea el objeto Spotify\n",
    "        self.sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "                                    client_secret=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "                                    redirect_uri=\"http://polaris/callback\",\n",
    "                                    scope=\"user-read-private user-read-playback-state user-modify-playback-state\"))\n",
    "        \n",
    "        # Se crea el objeto Natural Language\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"google-credentials.json\"\n",
    "        self.nl = language.LanguageServiceClient()\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_color(color):\n",
    "        for i in range(12):\n",
    "            driver.set_pixel(i, color[0], color[1], color[2])\n",
    "        driver.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def _speech_to_text():\n",
    "        text = None\n",
    "        r = sr.Recognizer()  \n",
    "        with sr.Microphone() as source:  \n",
    "            print(\"Dime algo:\")  \n",
    "            audio = r.listen(source)  \n",
    "            text = r.recognize_google(audio)  \n",
    "        print(\"Has dicho: {}\".format(text))\n",
    "        return text\n",
    "\n",
    "    # Se llama al metodo cuando se entiende la wake word\n",
    "    @staticmethod\n",
    "    def _wake_word_callback():\n",
    "        print('[wake word]\\n')\n",
    "        PicovoiceDemo._set_color(COLORS_RGB['purple'])\n",
    "\n",
    "    # Operaciones seg\\u00fan las orden entendida\n",
    "    def _inference_callback(self, inference):\n",
    "        print('{')\n",
    "        print(\"  is_understood : '%s',\" % 'true' if inference.is_understood else 'false')\n",
    "        if inference.is_understood:\n",
    "            print(\"  intent : '%s',\" % inference.intent)\n",
    "            if len(inference.slots) > 0:\n",
    "                print('  slots : {')\n",
    "                for slot, value in inference.slots.items():\n",
    "                    print(\"    '%s' : '%s',\" % (slot, value))\n",
    "                print('  }')\n",
    "        print('}\\n')\n",
    "\n",
    "        if inference.is_understood:\n",
    "            if inference.intent == 'cancion':\n",
    "                # Se pausa la reproduccion\n",
    "                self.sp.pause_playback() \n",
    "                \n",
    "                # Se pregunta al usuario la cancion\n",
    "                voice = AudioSegment.from_mp3(\"cancion.mp3\")\n",
    "                play(voice)\n",
    "\n",
    "                # Se obtiene la cancion\n",
    "                song = self._speech_to_text()  \n",
    "\n",
    "                # Se reproduce la canci\\u00f3n\n",
    "                searchResults = self.sp.search(song,1,0,\"track\")\n",
    "                track = searchResults['tracks']['items'][0]\n",
    "                self.sp.start_playback(uris=[track['uri']])\n",
    "\n",
    "                self._set_color(COLORS_RGB['off'])\n",
    "            elif inference.intent == 'album':\n",
    "                # Se pasa la reproduccion\n",
    "                self.sp.pause_playback() \n",
    "                \n",
    "                # Se pregunta al usuario el album\n",
    "                voice = AudioSegment.from_mp3(\"album.mp3\")\n",
    "                play(voice)\n",
    "\n",
    "                # Se obtiene el album\n",
    "                album = self._speech_to_text()  \n",
    "\n",
    "                # Se reproduce el album\n",
    "                searchResults = self.sp.search(album,1,0,\"album\")\n",
    "                album = searchResults['albums']['items'][0]\n",
    "                self.sp.start_playback(context_uri=album['uri'])\n",
    "                \n",
    "                self._set_color(COLORS_RGB['off'])\n",
    "            elif inference.intent == 'artista':\n",
    "                # Se pasa la reproduccion\n",
    "                self.sp.pause_playback() \n",
    "\n",
    "                # Se pregunta al usuario el artista\n",
    "                voice = AudioSegment.from_mp3(\"artista.mp3\")\n",
    "                play(voice)\n",
    "\n",
    "                # Se obtiene el artista\n",
    "                artist = self._speech_to_text()  \n",
    "\n",
    "                # Se reproduce el artista\n",
    "                searchResults = self.sp.search(artist,1,0,\"artist\")\n",
    "                artist = searchResults['artists']['items'][0]\n",
    "                self.sp.start_playback(context_uri=artist['uri'])\n",
    "                \n",
    "                self._set_color(COLORS_RGB['off'])\n",
    "            elif inference.intent == 'playlist':\n",
    "\n",
    "                # Se pasa la reproduccion\n",
    "                self.sp.pause_playback()\n",
    "                \n",
    "                # Se pregunta la playlist\n",
    "                voice = AudioSegment.from_mp3(\"playlist.mp3\")\n",
    "                play(voice)\n",
    "\n",
    "                # Se obtiene la playlist\n",
    "                playlist = self._speech_to_text()  \n",
    "\n",
    "                # Se reproduce la playlist\n",
    "                searchResults = self.sp.search(playlist,1,0,\"playlist\")\n",
    "                playlist = searchResults['playlists']['items'][0]\n",
    "                self.sp.start_playback(context_uri=playlist['uri'])\n",
    "\n",
    "                self._set_color(COLORS_RGB['off'])\n",
    "            elif inference.intent == 'playlistRec': \n",
    "                # Se pausa la reproduccion\n",
    "                self.sp.pause_playback() \n",
    "                \n",
    "                # Se pregunta como se encuentra \n",
    "                voice = AudioSegment.from_mp3(\"como_estas.mp3\")\n",
    "                play(voice)\n",
    "\n",
    "                # Analisis de texto\n",
    "                text = self._speech_to_text()\n",
    "                document = language.Document(content=text, type_=language.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "                # Detecta la emocion del texto\n",
    "                sentiment = self.nl.analyze_sentiment(request={'document': document}).document_sentiment\n",
    "\n",
    "                print(\"Text: {}\".format(text))\n",
    "                print(\"Sentiment: {}, {}\".format(sentiment.score, sentiment.magnitude))\n",
    "\n",
    "                # Se categorizan las emociones y se reproduce una lista de reproduccion\n",
    "                if sentiment.score > 0.25:\n",
    "                    # positiva\n",
    "                    print(\"Emocion positiva\")\n",
    "                    self._set_color(COLORS_RGB['red'])\n",
    "                    voice = AudioSegment.from_mp3(\"positiva.mp3\")\n",
    "                    play(voice)\n",
    "                    self.sp.start_playback(context_uri=\"spotify:playlist:37i9dQZF1DX9Dh2wgiAwVX\")\n",
    "                    self._set_color(COLORS_RGB['off'])\n",
    "                    \n",
    "                elif sentiment.score < 0.0:\n",
    "                    # negativa\n",
    "                    print(\"Emocion negativa\")\n",
    "                    self._set_color(COLORS_RGB['blue'])\n",
    "                    voice = AudioSegment.from_mp3(\"negativa.mp3\")\n",
    "                    play(voice)\n",
    "                    self.sp.start_playback(context_uri=\"spotify:playlist:37i9dQZF1DXdZjf8WgcTKM\")\n",
    "                    self._set_color(COLORS_RGB['off'])\n",
    "                    \n",
    "                elif sentiment.score == 0.0 and sentiment.magnitude >= 4.0:\n",
    "                    # mixta\n",
    "                    print(\"Emocion mixta\")\n",
    "                    self._set_color(COLORS_RGB['yellow'])\n",
    "                    voice = AudioSegment.from_mp3(\"mixta.mp3\")\n",
    "                    play(voice)\n",
    "                    self.sp.start_playback(context_uri=\"spotify:playlist:37i9dQZF1DX7qRKBHjmYIE\")\n",
    "                    self._set_color(COLORS_RGB['off'])\n",
    "                    \n",
    "                else:\n",
    "                    # neutra\n",
    "                    print(\"Emocion neutra\")\n",
    "                    self._set_color(COLORS_RGB['white'])\n",
    "                    voice = AudioSegment.from_mp3(\"neutra.mp3\")\n",
    "                    play(voice)\n",
    "                    self.sp.start_playback(context_uri=\"spotify:playlist:37i9dQZF1DWV1PBrIG2weG\") \n",
    "                    self._set_color(COLORS_RGB['off'])\n",
    "           \n",
    "            elif inference.intent == 'play':\n",
    "                self.sp.start_playback()\n",
    "                self._set_color(COLORS_RGB['off'])\n",
    "            elif inference.intent == 'pause':\n",
    "                    self.sp.pause_playback()\n",
    "                    self._set_color(COLORS_RGB['off'])\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "    def run(self):\n",
    "        pa = None\n",
    "        audio_stream = None\n",
    "\n",
    "        try:\n",
    "            # Se abre un stream de audio\n",
    "            pa = pyaudio.PyAudio()\n",
    "\n",
    "            audio_stream = pa.open(\n",
    "                rate=self._picovoice.sample_rate,\n",
    "                channels=1,\n",
    "                format=pyaudio.paInt16,\n",
    "                input=True,\n",
    "                frames_per_buffer=self._picovoice.frame_length)\n",
    "\n",
    "            print(self._context)\n",
    "\n",
    "            print('[Listening ...]')\n",
    "\n",
    "            # Se procesan los frames de audio y se pasan al objeto picovoice\n",
    "            while True:\n",
    "                pcm = audio_stream.read(self._picovoice.frame_length)\n",
    "                pcm = struct.unpack_from(\"h\" * self._picovoice.frame_length, pcm)\n",
    "\n",
    "                self._picovoice.process(pcm)\n",
    "        except KeyboardInterrupt:\n",
    "            sys.stdout.write('\\b' * 2)\n",
    "            print('Stopping ...')\n",
    "        finally:\n",
    "            power.close()\n",
    "            if audio_stream is not None:\n",
    "                audio_stream.close()\n",
    "\n",
    "            if pa is not None:\n",
    "                pa.terminate()\n",
    "\n",
    "            self._picovoice.delete()\n",
    "\n",
    "def main():\n",
    "    # Se indica la ruta de los archivos de palabra clave y de contexto\n",
    "    o = PicovoiceDemo('picovoice_raspberry-pi.ppn', 'Polaris_es_raspberry-pi_2021-05-15-utc_v1_6_0.rhn')\n",
    "    o.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
